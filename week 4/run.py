import ollama

# ì‚¬ìš©í•  ëª¨ë¸ ì´ë¦„
model_name = "exaone3.5:2.4b"

# ëŒ€í™” ížˆìŠ¤í† ë¦¬ (ë¦¬ìŠ¤íŠ¸ë¡œ ê´€ë¦¬)
chat_history = []
history_limit = 10  # ìµœëŒ€ 10ê°œë§Œ ìœ ì§€

def ask(question):
    global chat_history

    # ì‚¬ìš©ìž ë©”ì‹œì§€ ì¶”ê°€
    chat_history.append({"role": "user", "content": question})

    # ížˆìŠ¤í† ë¦¬ ê¸¸ì´ ì œí•œ
    if len(chat_history) > history_limit:
        chat_history = chat_history[-history_limit:]

    # Ollama í˜¸ì¶œ
    response = ollama.chat(
        model=model_name,
        messages=chat_history
    )

    answer = response["message"]["content"].strip()

    # ì–´ì‹œìŠ¤í„´íŠ¸ ë‹µë³€ë„ ížˆìŠ¤í† ë¦¬ì— ì¶”ê°€
    chat_history.append({"role": "assistant", "content": answer})

    # ížˆìŠ¤í† ë¦¬ ê¸¸ì´ ì œí•œ
    if len(chat_history) > history_limit:
        chat_history = chat_history[-history_limit:]

    return answer

if __name__ == "__main__":
    print("ðŸ’¬ Ollama ëŒ€í™” ì‹œìž‘ (ì¢…ë£Œí•˜ë ¤ë©´ 'exit' ìž…ë ¥)")
    while True:
        q = input("\në‚˜: ")
        if q.lower() in ["exit", "quit", "ì¢…ë£Œ"]:
            print("ðŸ‘‹ ëŒ€í™”ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            break
        answer = ask(q)
        print(f"AI: {answer}")
